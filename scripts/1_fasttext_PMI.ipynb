{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "670d1e55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T05:09:38.960369Z",
     "start_time": "2025-08-23T05:09:38.948017Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47615060ed864a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the corpus\n",
    "with open (\"/srv/data/enemy-christ/large-data/grouped_df.pkl\", \"rb\") as f:\n",
    "    grouped = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff0d4eb27d19cd5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T05:07:32.163008Z",
     "start_time": "2025-08-23T05:07:30.878211Z"
    }
   },
   "outputs": [],
   "source": [
    "# make your subcorpora dataframes from \"enemy_subcorpus\" column\n",
    "christian_0_300 = grouped[grouped[\"enemy_subcorpus\"]==\"christian_0_300\"]\n",
    "christian_300_600 = grouped[grouped[\"enemy_subcorpus\"]==\"christian_300_600\"]\n",
    "pagan_0_300 = grouped[grouped[\"enemy_subcorpus\"]==\"pagan_0_300\"]\n",
    "pagan_300_600 = grouped[grouped[\"enemy_subcorpus\"]==\"pagan_300_600\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3aebd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "fdist1 = FreqDist(word for sent in christian_0_300['lamma_sentence'] for word in sent.split())\n",
    "fdist2 = FreqDist(word for sent in christian_300_600['lamma_sentence'] for word in sent.split())\n",
    "fdist3 = FreqDist(word for sent in pagan_0_300['lamma_sentence'] for word in sent.split())\n",
    "fdist4 = FreqDist(word for sent in pagan_300_600['lamma_sentence'] for word in sent.split())\n",
    "\n",
    "# Find words that appear >=10 times in all subcorpora\n",
    "common_words = set(\n",
    "    word for word in fdist1 if fdist1[word] >= 10\n",
    ") & set(\n",
    "    word for word in fdist2 if fdist2[word] >= 10\n",
    ") & set(\n",
    "    word for word in fdist3 if fdist3[word] >= 10\n",
    ") & set(\n",
    "    word for word in fdist4 if fdist4[word] >= 10\n",
    ")\n",
    "\n",
    "# Filter each subcorpus to only keep those words\n",
    "words1 = {word: fdist1[word] for word in common_words}\n",
    "words2 = {word: fdist2[word] for word in common_words}\n",
    "words3 = {word: fdist3[word] for word in common_words}\n",
    "words4 = {word: fdist4[word] for word in common_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f80237aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "from gensim.utils import RULE_KEEP, RULE_DISCARD, RULE_DEFAULT\n",
    "\n",
    "class EpochLogger(CallbackAny2Vec):\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "    def on_epoch_begin(self, model):\n",
    "        print(f\"Epoch #{self.epoch} start\")\n",
    "    def on_epoch_end(self, model):\n",
    "        print(f\"Epoch #{self.epoch} end\")\n",
    "        self.epoch += 1\n",
    "\n",
    "def train_fasttext_on_subcorpus(sentences, model_path):\n",
    "    #sentences = [s.split() for s in sentences]\n",
    "    model = FastText(\n",
    "        vector_size=100,\n",
    "        window=10, #vojta used 10\n",
    "        min_count=1,\n",
    "        sg=1,\n",
    "        workers=16,\n",
    "    )\n",
    "    model.build_vocab_from_freq(word_freq=sentences)\n",
    "    model.train(\n",
    "        corpus_iterable=sentences,\n",
    "        total_examples=len(sentences),\n",
    "        epochs=20,\n",
    "        callbacks=[EpochLogger()]\n",
    "    )\n",
    "    model.save(model_path)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f50d705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0 start\n",
      "Epoch #0 end\n",
      "Epoch #1 start\n",
      "Epoch #1 end\n",
      "Epoch #2 start\n",
      "Epoch #2 end\n",
      "Epoch #3 start\n",
      "Epoch #3 end\n",
      "Epoch #4 start\n",
      "Epoch #4 end\n",
      "Epoch #5 start\n",
      "Epoch #5 end\n",
      "Epoch #6 start\n",
      "Epoch #6 end\n",
      "Epoch #7 start\n",
      "Epoch #7 end\n",
      "Epoch #8 start\n",
      "Epoch #8 end\n",
      "Epoch #9 start\n",
      "Epoch #9 end\n",
      "Epoch #10 start\n",
      "Epoch #10 end\n",
      "Epoch #11 start\n",
      "Epoch #11 end\n",
      "Epoch #12 start\n",
      "Epoch #12 end\n",
      "Epoch #13 start\n",
      "Epoch #13 end\n",
      "Epoch #14 start\n",
      "Epoch #14 end\n",
      "Epoch #15 start\n",
      "Epoch #15 end\n",
      "Epoch #16 start\n",
      "Epoch #16 end\n",
      "Epoch #17 start\n",
      "Epoch #17 end\n",
      "Epoch #18 start\n",
      "Epoch #18 end\n",
      "Epoch #19 start\n",
      "Epoch #19 end\n",
      "Epoch #0 start\n",
      "Epoch #0 end\n",
      "Epoch #1 start\n",
      "Epoch #1 end\n",
      "Epoch #2 start\n",
      "Epoch #2 end\n",
      "Epoch #3 start\n",
      "Epoch #3 end\n",
      "Epoch #4 start\n",
      "Epoch #4 end\n",
      "Epoch #5 start\n",
      "Epoch #5 end\n",
      "Epoch #6 start\n",
      "Epoch #6 end\n",
      "Epoch #7 start\n",
      "Epoch #7 end\n",
      "Epoch #8 start\n",
      "Epoch #8 end\n",
      "Epoch #9 start\n",
      "Epoch #9 end\n",
      "Epoch #10 start\n",
      "Epoch #10 end\n",
      "Epoch #11 start\n",
      "Epoch #11 end\n",
      "Epoch #12 start\n",
      "Epoch #12 end\n",
      "Epoch #13 start\n",
      "Epoch #13 end\n",
      "Epoch #14 start\n",
      "Epoch #14 end\n",
      "Epoch #15 start\n",
      "Epoch #15 end\n",
      "Epoch #16 start\n",
      "Epoch #16 end\n",
      "Epoch #17 start\n",
      "Epoch #17 end\n",
      "Epoch #18 start\n",
      "Epoch #18 end\n",
      "Epoch #19 start\n",
      "Epoch #19 end\n",
      "Epoch #0 start\n",
      "Epoch #0 end\n",
      "Epoch #1 start\n",
      "Epoch #1 end\n",
      "Epoch #2 start\n",
      "Epoch #2 end\n",
      "Epoch #3 start\n",
      "Epoch #3 end\n",
      "Epoch #4 start\n",
      "Epoch #4 end\n",
      "Epoch #5 start\n",
      "Epoch #5 end\n",
      "Epoch #6 start\n",
      "Epoch #6 end\n",
      "Epoch #7 start\n",
      "Epoch #7 end\n",
      "Epoch #8 start\n",
      "Epoch #8 end\n",
      "Epoch #9 start\n",
      "Epoch #9 end\n",
      "Epoch #10 start\n",
      "Epoch #10 end\n",
      "Epoch #11 start\n",
      "Epoch #11 end\n",
      "Epoch #12 start\n",
      "Epoch #12 end\n",
      "Epoch #13 start\n",
      "Epoch #13 end\n",
      "Epoch #14 start\n",
      "Epoch #14 end\n",
      "Epoch #15 start\n",
      "Epoch #15 end\n",
      "Epoch #16 start\n",
      "Epoch #16 end\n",
      "Epoch #17 start\n",
      "Epoch #17 end\n",
      "Epoch #18 start\n",
      "Epoch #18 end\n",
      "Epoch #19 start\n",
      "Epoch #19 end\n",
      "Epoch #0 start\n",
      "Epoch #0 end\n",
      "Epoch #1 start\n",
      "Epoch #1 end\n",
      "Epoch #2 start\n",
      "Epoch #2 end\n",
      "Epoch #3 start\n",
      "Epoch #3 end\n",
      "Epoch #4 start\n",
      "Epoch #4 end\n",
      "Epoch #5 start\n",
      "Epoch #5 end\n",
      "Epoch #6 start\n",
      "Epoch #6 end\n",
      "Epoch #7 start\n",
      "Epoch #7 end\n",
      "Epoch #8 start\n",
      "Epoch #8 end\n",
      "Epoch #9 start\n",
      "Epoch #9 end\n",
      "Epoch #10 start\n",
      "Epoch #10 end\n",
      "Epoch #11 start\n",
      "Epoch #11 end\n",
      "Epoch #12 start\n",
      "Epoch #12 end\n",
      "Epoch #13 start\n",
      "Epoch #13 end\n",
      "Epoch #14 start\n",
      "Epoch #14 end\n",
      "Epoch #15 start\n",
      "Epoch #15 end\n",
      "Epoch #16 start\n",
      "Epoch #16 end\n",
      "Epoch #17 start\n",
      "Epoch #17 end\n",
      "Epoch #18 start\n",
      "Epoch #18 end\n",
      "Epoch #19 start\n",
      "Epoch #19 end\n",
      "CPU times: user 5.76 s, sys: 2.18 s, total: 7.94 s\n",
      "Wall time: 7.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Example usage for each subcorpus:\n",
    "christian_0_300_model = train_fasttext_on_subcorpus(\n",
    "    words1, \"../data/large-data/fasttext_christian_0_300.model\"\n",
    ")\n",
    "christian_300_600_model = train_fasttext_on_subcorpus(\n",
    "    words2, \"../data/large-data/fasttext_christian_300_600.model\"\n",
    ")\n",
    "pagan_0_300_model = train_fasttext_on_subcorpus(\n",
    "    words3, \"../data/large-data/fasttext_pagan_0_300.model\"\n",
    ")\n",
    "pagan_300_600_model = train_fasttext_on_subcorpus(\n",
    "    words4, \"../data/large-data/fasttext_pagan_300_600.model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4e78e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "# Load every FastText model for each subcorpus into a variable\n",
    "christian_0_300_model = FastText.load(\"../data/large-data/fasttext_christian_0_300.model\")\n",
    "christian_300_600_model = FastText.load(\"../data/large-data/fasttext_christian_300_600.model\")\n",
    "pagan_0_300_model = FastText.load(\"../data/large-data/fasttext_pagan_0_300.model\")\n",
    "pagan_300_600_model = FastText.load(\"../data/large-data/fasttext_pagan_300_600.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b488e653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 3929 samples in 0.001s...\n",
      "[t-SNE] Computed neighbors for 3929 samples in 0.087s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 3929\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 3929\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 3929\n",
      "[t-SNE] Computed conditional probabilities for sample 3929 / 3929\n",
      "[t-SNE] Mean sigma: 0.003285\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 83.338364\n",
      "[t-SNE] KL divergence after 1000 iterations: 3.307391\n",
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 3929 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 3929 samples in 0.039s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 3929\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 3929\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 3929\n",
      "[t-SNE] Computed conditional probabilities for sample 3929 / 3929\n",
      "[t-SNE] Mean sigma: 0.003289\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 83.780388\n",
      "[t-SNE] KL divergence after 1000 iterations: 3.288627\n",
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 3929 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 3929 samples in 0.039s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 3929\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 3929\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 3929\n",
      "[t-SNE] Computed conditional probabilities for sample 3929 / 3929\n",
      "[t-SNE] Mean sigma: 0.003288\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 84.364677\n",
      "[t-SNE] KL divergence after 1000 iterations: 3.285532\n",
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 3929 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 3929 samples in 0.038s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 3929\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 3929\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 3929\n",
      "[t-SNE] Computed conditional probabilities for sample 3929 / 3929\n",
      "[t-SNE] Mean sigma: 0.003290\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 84.480377\n",
      "[t-SNE] KL divergence after 1000 iterations: 3.281834\n",
      "CPU times: user 4min 32s, sys: 7.51 s, total: 4min 39s\n",
      "Wall time: 17.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "models = [\n",
    "    (christian_0_300_model, \"christian_0_300\", 0),\n",
    "    (christian_300_600_model, \"christian_300_600\", 1),\n",
    "    (pagan_0_300_model, \"pagan_0_300\", 2),\n",
    "    (pagan_300_600_model, \"pagan_300_600\", 3),\n",
    "]\n",
    "\n",
    "dfs = []\n",
    "for model, label, z in models:\n",
    "    vocab = list(model.wv.index_to_key)\n",
    "    vecs = [model.wv[w] for w in vocab]\n",
    "    tsne = TSNE(n_components=2, random_state=42, verbose=1)\n",
    "    tsne_result = tsne.fit_transform(np.array(vecs))\n",
    "    df = pd.DataFrame({\n",
    "        \"word\": vocab,\n",
    "        \"x\": tsne_result[:, 0],\n",
    "        \"y\": tsne_result[:, 1],\n",
    "        \"z\": z,\n",
    "        \"subcorpus\": label\n",
    "    })\n",
    "    dfs.append(df)\n",
    "\n",
    "df_plot = pd.concat(dfs, ignore_index=True)\n",
    "df_plot.to_pickle(\"../data/large-data/df_plot.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0795395",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = pd.read_pickle(\"../data/large-data/df_plot.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a962111e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.4 s, sys: 1min 5s, total: 1min 23s\n",
      "Wall time: 2.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Precompute nearest neighbors for all words in all subcorpora and save to pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "neighbors_dict = defaultdict(dict)\n",
    "model_map = {\n",
    "    \"christian_0_300\": christian_0_300_model,\n",
    "    \"christian_300_600\": christian_300_600_model,\n",
    "    \"pagan_0_300\": pagan_0_300_model,\n",
    "    \"pagan_300_600\": pagan_300_600_model,\n",
    "}\n",
    "N_NEIGHBORS = 100\n",
    "\n",
    "for subcorpus, model in model_map.items():\n",
    "    for word in model.wv.index_to_key:\n",
    "        try:\n",
    "            neighbors = model.wv.most_similar(word, topn=N_NEIGHBORS)  # returns list of (word, similarity)\n",
    "        except KeyError:\n",
    "            neighbors = []\n",
    "        neighbors_dict[subcorpus][word] = neighbors\n",
    "\n",
    "import pickle\n",
    "with open(\"../data/large-data/word_neighbors.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dict(neighbors_dict), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8743e2c",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1565d115",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "grouped = pd.read_pickle('../data/large-data/grouped_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1183dd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make your subcorpora dataframes from \"enemy_subcorpus\" column\n",
    "christian_0_300 = grouped[grouped[\"enemy_subcorpus\"]==\"christian_0_300\"]\n",
    "christian_300_600 = grouped[grouped[\"enemy_subcorpus\"]==\"christian_300_600\"]\n",
    "pagan_0_300 = grouped[grouped[\"enemy_subcorpus\"]==\"pagan_0_300\"]\n",
    "pagan_300_600 = grouped[grouped[\"enemy_subcorpus\"]==\"pagan_300_600\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cd231cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "# Find most frequent words (lowercased)\n",
    "fdist1 = FreqDist(word.lower() for sent in christian_0_300['lamma_sentence'] for word in sent.split())\n",
    "fdist2 = FreqDist(word.lower() for sent in christian_300_600['lamma_sentence'] for word in sent.split())\n",
    "fdist3 = FreqDist(word.lower() for sent in pagan_0_300['lamma_sentence'] for word in sent.split())\n",
    "fdist4 = FreqDist(word.lower() for sent in pagan_300_600['lamma_sentence'] for word in sent.split())\n",
    "\n",
    "# Find words that appear >=10 times in all subcorpora\n",
    "vocab = set(\n",
    "    word for word in fdist1 if fdist1[word] >= 10\n",
    ") & set(\n",
    "    word for word in fdist2 if fdist2[word] >= 10\n",
    ") & set(\n",
    "    word for word in fdist3 if fdist3[word] >= 10\n",
    ") & set(\n",
    "    word for word in fdist4 if fdist4[word] >= 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce9d7fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def compute_tfidf(sentences):\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        #min_df=10,\n",
    "        #max_features=1000,\n",
    "        vocabulary=vocab, #use common vocab\n",
    "    )\n",
    "    tfidf_matrix = vectorizer.fit_transform(sentences)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    return [tfidf_matrix, feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa727a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_christian_0_300 = compute_tfidf(christian_0_300['lamma_sentence'])\n",
    "tfidf_christian_300_600 = compute_tfidf(christian_300_600['lamma_sentence'])\n",
    "tfidf_pagan_0_300 = compute_tfidf(pagan_0_300['lamma_sentence'])\n",
    "tfidf_pagan_300_600 = compute_tfidf(pagan_300_600['lamma_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7e884b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_weighted_cooccurrence(tfidf_data):\n",
    "    \"\"\"\n",
    "    Given [tfidf_matrix, feature_names] as returned by compute_tfidf,\n",
    "    returns a DataFrame of TF-IDF weighted term-term association.\n",
    "    \"\"\"\n",
    "    tfidf_matrix, feature_names = tfidf_data\n",
    "    weighted_cooccurrence = (tfidf_matrix.T @ tfidf_matrix)\n",
    "    # Remove self-association (diagonal)\n",
    "    np.fill_diagonal(weighted_cooccurrence.toarray(), 0)\n",
    "    return pd.DataFrame(\n",
    "        weighted_cooccurrence.toarray(),\n",
    "        index=feature_names,\n",
    "        columns=feature_names\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61f6c460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Compute co-occurrence matrices for all subcorpora\n",
    "cooc_christian_0_300 = compute_weighted_cooccurrence(tfidf_christian_0_300)\n",
    "cooc_christian_300_600 = compute_weighted_cooccurrence(tfidf_christian_300_600)\n",
    "cooc_pagan_0_300 = compute_weighted_cooccurrence(tfidf_pagan_0_300)\n",
    "cooc_pagan_300_600 = compute_weighted_cooccurrence(tfidf_pagan_300_600)\n",
    "\n",
    "tfidf_cooc = {\n",
    "    \"christian_0_300\": cooc_christian_0_300,\n",
    "    \"christian_300_600\": cooc_christian_300_600,\n",
    "    \"pagan_0_300\": cooc_pagan_0_300,\n",
    "    \"pagan_300_600\": cooc_pagan_300_600,\n",
    "}\n",
    "\n",
    "with open(\"../data/large-data/tfidf_cooc.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tfidf_cooc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c699f43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "φίλος       7.418677\n",
       "ποιέω       4.051001\n",
       "εἰμί        3.539491\n",
       "θεός        3.526939\n",
       "πολέμιος    2.419786\n",
       "πόλις       2.071748\n",
       "ἔχω         1.945513\n",
       "γίγνομαι    1.772934\n",
       "δίκαιος     1.726710\n",
       "ἀνήρ        1.623366\n",
       "πολύς       1.445067\n",
       "ἄνθρωπος    1.376607\n",
       "κακός       1.362612\n",
       "νομίζω      1.331194\n",
       "πᾶς         1.327142\n",
       "δίδωμι      1.313136\n",
       "οἶδα        1.272845\n",
       "δίκη        1.267826\n",
       "ἥκω         1.092527\n",
       "ἡγέομαι     1.092482\n",
       "Name: ἐχθρός, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def strongest_cooccurrences(tfidf_cooc, target_word, top_n=20):\n",
    "    \"\"\"\n",
    "    Returns the top_n strongest co-occurring words with target_word from the co-occurrence DataFrame.\n",
    "    \"\"\"\n",
    "    for subcorpus, cooc_df in tfidf_cooc.items():\n",
    "        if target_word not in cooc_df.columns:\n",
    "            print(f\"'{target_word}' not found in vocabulary.\")\n",
    "            return None\n",
    "    # Get co-occurrence scores for the target word, sort descending, exclude itself\n",
    "    scores = cooc_df[target_word].drop(target_word).sort_values(ascending=False)\n",
    "    return scores.head(top_n)\n",
    "\n",
    "strongest_cooccurrences(tfidf_cooc, \"ἐχθρός\", top_n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67106a2e",
   "metadata": {},
   "source": [
    "# PMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "484aab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "grouped = pd.read_pickle('../data/large-data/grouped_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5de4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make your subcorpora dataframes from \"enemy_subcorpus\" column\n",
    "christian_0_300 = grouped[grouped[\"enemy_subcorpus\"]==\"christian_0_300\"]\n",
    "christian_300_600 = grouped[grouped[\"enemy_subcorpus\"]==\"christian_300_600\"]\n",
    "pagan_0_300 = grouped[grouped[\"enemy_subcorpus\"]==\"pagan_0_300\"]\n",
    "pagan_300_600 = grouped[grouped[\"enemy_subcorpus\"]==\"pagan_300_600\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56446dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "# Find most frequent words (lowercased)\n",
    "fdist1 = FreqDist(word.lower() for sent in christian_0_300['lamma_sentence'] for word in sent.split())\n",
    "fdist2 = FreqDist(word.lower() for sent in christian_300_600['lamma_sentence'] for word in sent.split())\n",
    "fdist3 = FreqDist(word.lower() for sent in pagan_0_300['lamma_sentence'] for word in sent.split())\n",
    "fdist4 = FreqDist(word.lower() for sent in pagan_300_600['lamma_sentence'] for word in sent.split())\n",
    "\n",
    "# Find words that appear >=10 times in all subcorpora\n",
    "vocab = set(\n",
    "    word for word in fdist1 if fdist1[word] >= 10\n",
    ") & set(\n",
    "    word for word in fdist2 if fdist2[word] >= 10\n",
    ") & set(\n",
    "    word for word in fdist3 if fdist3[word] >= 10\n",
    ") & set(\n",
    "    word for word in fdist4 if fdist4[word] >= 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66a49ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "\n",
    "def compute_pmi_from_sentences(sentences, vocab=vocab, min_count=10):\n",
    "    # Tokenize sentences\n",
    "    tokenized = [sent.split() for sent in sentences]\n",
    "    # Flatten for unigram counts\n",
    "    all_words = [w for sent in tokenized for w in sent]\n",
    "    unigram_counts = Counter(all_words)\n",
    "    # Filter vocab by min_count\n",
    "    if vocab is None:\n",
    "        vocab = set([w for w, c in unigram_counts.items() if c >= min_count])\n",
    "    # Count co-occurrences (within sentence)\n",
    "    cooc_counts = Counter()\n",
    "    for sent in tokenized:\n",
    "        words = [w for w in sent if w in vocab]\n",
    "        for w1, w2 in combinations(sorted(set(words)), 2):\n",
    "            cooc_counts[(w1, w2)] += 1\n",
    "    N = len(tokenized)\n",
    "    results = []\n",
    "    for (w1, w2), c_xy in cooc_counts.items():\n",
    "        c_x = unigram_counts[w1]\n",
    "        c_y = unigram_counts[w2]\n",
    "        # Probabilities\n",
    "        p_x = c_x / N\n",
    "        p_y = c_y / N\n",
    "        p_xy = c_xy / N\n",
    "        if p_xy > 0:\n",
    "            pmi = np.log(p_xy / (p_x * p_y))\n",
    "            results.append({'word1': w1, 'word2': w2, 'pmi': pmi, 'count': c_xy})\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee181744",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmi_christian_0_300 = compute_pmi_from_sentences(christian_0_300['lamma_sentence'])\n",
    "pmi_christian_300_600 = compute_pmi_from_sentences(christian_300_600['lamma_sentence'])\n",
    "pmi_pagan_0_300 = compute_pmi_from_sentences(pagan_0_300['lamma_sentence'])\n",
    "pmi_pagan_300_600 = compute_pmi_from_sentences(pagan_300_600['lamma_sentence'])\n",
    "\n",
    "import pickle\n",
    "\n",
    "pmi_dict = {\n",
    "    \"christian_0_300\": pmi_christian_0_300,\n",
    "    \"christian_300_600\": pmi_christian_300_600,\n",
    "    \"pagan_0_300\": pmi_pagan_0_300,\n",
    "    \"pagan_300_600\": pmi_pagan_300_600,\n",
    "}\n",
    "\n",
    "with open(\"../data/large-data/pmi_all_subcorpora.pkl\", \"wb\") as f:\n",
    "    pickle.dump(pmi_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfd17f4",
   "metadata": {},
   "source": [
    "# text to label for zdenka\n",
    "Zjeveni = lagt_tlg0031.tlg027\n",
    "Matous = lagt_tlg0031.tlg001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560855e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>grela_source</th>\n",
       "      <th>grela_id</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>not_before</th>\n",
       "      <th>not_after</th>\n",
       "      <th>lagt_tlg_epithet</th>\n",
       "      <th>lagt_genre</th>\n",
       "      <th>lagt_provenience</th>\n",
       "      <th>...</th>\n",
       "      <th>noscemus_discipline</th>\n",
       "      <th>title_short</th>\n",
       "      <th>emlap_noscemus_id</th>\n",
       "      <th>place_publication</th>\n",
       "      <th>place_geonames</th>\n",
       "      <th>author_viaf</th>\n",
       "      <th>title_viaf</th>\n",
       "      <th>date_random</th>\n",
       "      <th>token_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lagt_tlg0545.tlg003_92</td>\n",
       "      <td>lagt</td>\n",
       "      <td>lagt_tlg0545.tlg003</td>\n",
       "      <td>Aelian</td>\n",
       "      <td>ἐκ τῶν Αἰλιανοῦ ἀγροικικῶν ἐπιστολῶν</td>\n",
       "      <td>175.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>['Sophistae']</td>\n",
       "      <td>[]</td>\n",
       "      <td>pagan</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>186.0</td>\n",
       "      <td>2455</td>\n",
       "      <td>τί γὰρ παθὼν ῥυθμίζεις με καὶ πρᾶον ἀποφῆναι γ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lagt_tlg2200.tlg00427_48</td>\n",
       "      <td>lagt</td>\n",
       "      <td>lagt_tlg2200.tlg00427</td>\n",
       "      <td>Libanius</td>\n",
       "      <td>Oratio 27</td>\n",
       "      <td>385.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>['Rhetorici' 'Sophistae']</td>\n",
       "      <td>[]</td>\n",
       "      <td>pagan</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>385.0</td>\n",
       "      <td>5267</td>\n",
       "      <td>οὐδέν οὖν ἕτερον λέγεις ἤ ὅτι φιλοῦσι τούς πον...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lagt_tlg0031.tlg014_29</td>\n",
       "      <td>lagt</td>\n",
       "      <td>lagt_tlg0031.tlg014</td>\n",
       "      <td>Pauline literature</td>\n",
       "      <td>New Testament - 2 Thessalonians</td>\n",
       "      <td>80.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>christian</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.0</td>\n",
       "      <td>941</td>\n",
       "      <td>καὶ μὴ ὡς ἐχθρὸν ἡγεῖσθε, ἀλλὰ νουθετεῖτε ὡς ἀ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lagt_tlg0007.tlg070_4</td>\n",
       "      <td>lagt</td>\n",
       "      <td>lagt_tlg0007.tlg070</td>\n",
       "      <td>Plutarch</td>\n",
       "      <td>Πῶς ἄν τις διακρίνειε τὸν κόλακα τοῦ φίλου</td>\n",
       "      <td>96.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>['Biographi' 'Philosophici/-ae']</td>\n",
       "      <td>[]</td>\n",
       "      <td>pagan</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.0</td>\n",
       "      <td>13729</td>\n",
       "      <td>εἰ δὲ δὴ θεῖον ἡ ἀλήθεια καὶ \" πάντων μὲν ἀγαθ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lagt_tlg0007.tlg070_30</td>\n",
       "      <td>lagt</td>\n",
       "      <td>lagt_tlg0007.tlg070</td>\n",
       "      <td>Plutarch</td>\n",
       "      <td>Πῶς ἄν τις διακρίνειε τὸν κόλακα τοῦ φίλου</td>\n",
       "      <td>96.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>['Biographi' 'Philosophici/-ae']</td>\n",
       "      <td>[]</td>\n",
       "      <td>pagan</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.0</td>\n",
       "      <td>13729</td>\n",
       "      <td>ἡμεῖς δέ, εἰ μηδαμῆ μηδαμῶς ἐπαινοῦμεν τὸ \" ἐρ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3461</th>\n",
       "      <td>lagt_tlg0007.tlg027_134</td>\n",
       "      <td>lagt</td>\n",
       "      <td>lagt_tlg0007.tlg027</td>\n",
       "      <td>Plutarch</td>\n",
       "      <td>Philopoemen</td>\n",
       "      <td>68.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>['Biographi' 'Philosophici/-ae']</td>\n",
       "      <td>[]</td>\n",
       "      <td>pagan</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.0</td>\n",
       "      <td>6386</td>\n",
       "      <td>ἦν μὲν γὰρ ἐστεφανωμένους ἰδεῖν, ἦν δὲ τοὺς αὐ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3462</th>\n",
       "      <td>lagt_tlg0007.tlg035_60</td>\n",
       "      <td>lagt</td>\n",
       "      <td>lagt_tlg0007.tlg035</td>\n",
       "      <td>Plutarch</td>\n",
       "      <td>Κίμων</td>\n",
       "      <td>96.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>['Biographi' 'Philosophici/-ae']</td>\n",
       "      <td>[]</td>\n",
       "      <td>pagan</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101.0</td>\n",
       "      <td>6645</td>\n",
       "      <td>τὸν δ’ ὑπὸ τοῦ ψόφου ταραχθέντα καὶ σπασάμενον...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3463</th>\n",
       "      <td>lagt_tlg0007.tlg035_153</td>\n",
       "      <td>lagt</td>\n",
       "      <td>lagt_tlg0007.tlg035</td>\n",
       "      <td>Plutarch</td>\n",
       "      <td>Κίμων</td>\n",
       "      <td>96.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>['Biographi' 'Philosophici/-ae']</td>\n",
       "      <td>[]</td>\n",
       "      <td>pagan</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101.0</td>\n",
       "      <td>6645</td>\n",
       "      <td>ἐκεῖθεν δὲ ῥᾳδίως ἐπιβῆναι Μακεδονίας καὶ πολλ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3464</th>\n",
       "      <td>lagt_tlg0007.tlg035_195</td>\n",
       "      <td>lagt</td>\n",
       "      <td>lagt_tlg0007.tlg035</td>\n",
       "      <td>Plutarch</td>\n",
       "      <td>Κίμων</td>\n",
       "      <td>96.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>['Biographi' 'Philosophici/-ae']</td>\n",
       "      <td>[]</td>\n",
       "      <td>pagan</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101.0</td>\n",
       "      <td>6645</td>\n",
       "      <td>ἡ δὲ βουλὴ τῶν πεντακοσίων πυθομένη καὶ φοβηθε...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3465</th>\n",
       "      <td>lagt_tlg0007.tlg035_212</td>\n",
       "      <td>lagt</td>\n",
       "      <td>lagt_tlg0007.tlg035</td>\n",
       "      <td>Plutarch</td>\n",
       "      <td>Κίμων</td>\n",
       "      <td>96.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>['Biographi' 'Philosophici/-ae']</td>\n",
       "      <td>[]</td>\n",
       "      <td>pagan</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101.0</td>\n",
       "      <td>6645</td>\n",
       "      <td>τὸ δὲ μῖγμα τῆς φωνῆς Μῆδον ἀποδηλοῖ τὸν ἐχθρόν·</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3466 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   sentence_id grela_source               grela_id  \\\n",
       "0       lagt_tlg0545.tlg003_92         lagt    lagt_tlg0545.tlg003   \n",
       "1     lagt_tlg2200.tlg00427_48         lagt  lagt_tlg2200.tlg00427   \n",
       "2       lagt_tlg0031.tlg014_29         lagt    lagt_tlg0031.tlg014   \n",
       "3        lagt_tlg0007.tlg070_4         lagt    lagt_tlg0007.tlg070   \n",
       "4       lagt_tlg0007.tlg070_30         lagt    lagt_tlg0007.tlg070   \n",
       "...                        ...          ...                    ...   \n",
       "3461   lagt_tlg0007.tlg027_134         lagt    lagt_tlg0007.tlg027   \n",
       "3462    lagt_tlg0007.tlg035_60         lagt    lagt_tlg0007.tlg035   \n",
       "3463   lagt_tlg0007.tlg035_153         lagt    lagt_tlg0007.tlg035   \n",
       "3464   lagt_tlg0007.tlg035_195         lagt    lagt_tlg0007.tlg035   \n",
       "3465   lagt_tlg0007.tlg035_212         lagt    lagt_tlg0007.tlg035   \n",
       "\n",
       "                  author                                       title  \\\n",
       "0                 Aelian        ἐκ τῶν Αἰλιανοῦ ἀγροικικῶν ἐπιστολῶν   \n",
       "1               Libanius                                   Oratio 27   \n",
       "2     Pauline literature             New Testament - 2 Thessalonians   \n",
       "3               Plutarch  Πῶς ἄν τις διακρίνειε τὸν κόλακα τοῦ φίλου   \n",
       "4               Plutarch  Πῶς ἄν τις διακρίνειε τὸν κόλακα τοῦ φίλου   \n",
       "...                  ...                                         ...   \n",
       "3461            Plutarch                                 Philopoemen   \n",
       "3462            Plutarch                                       Κίμων   \n",
       "3463            Plutarch                                       Κίμων   \n",
       "3464            Plutarch                                       Κίμων   \n",
       "3465            Plutarch                                       Κίμων   \n",
       "\n",
       "      not_before  not_after                  lagt_tlg_epithet lagt_genre  \\\n",
       "0          175.0      235.0                     ['Sophistae']         []   \n",
       "1          385.0      385.0         ['Rhetorici' 'Sophistae']         []   \n",
       "2           80.0      115.0                                []         []   \n",
       "3           96.0      120.0  ['Biographi' 'Philosophici/-ae']         []   \n",
       "4           96.0      120.0  ['Biographi' 'Philosophici/-ae']         []   \n",
       "...          ...        ...                               ...        ...   \n",
       "3461        68.0      120.0  ['Biographi' 'Philosophici/-ae']         []   \n",
       "3462        96.0      114.0  ['Biographi' 'Philosophici/-ae']         []   \n",
       "3463        96.0      114.0  ['Biographi' 'Philosophici/-ae']         []   \n",
       "3464        96.0      114.0  ['Biographi' 'Philosophici/-ae']         []   \n",
       "3465        96.0      114.0  ['Biographi' 'Philosophici/-ae']         []   \n",
       "\n",
       "     lagt_provenience  ... noscemus_discipline title_short emlap_noscemus_id  \\\n",
       "0               pagan  ...                None        None               NaN   \n",
       "1               pagan  ...                None        None               NaN   \n",
       "2           christian  ...                None        None               NaN   \n",
       "3               pagan  ...                None        None               NaN   \n",
       "4               pagan  ...                None        None               NaN   \n",
       "...               ...  ...                 ...         ...               ...   \n",
       "3461            pagan  ...                None        None               NaN   \n",
       "3462            pagan  ...                None        None               NaN   \n",
       "3463            pagan  ...                None        None               NaN   \n",
       "3464            pagan  ...                None        None               NaN   \n",
       "3465            pagan  ...                None        None               NaN   \n",
       "\n",
       "     place_publication  place_geonames author_viaf title_viaf  date_random  \\\n",
       "0                 None            None         NaN        NaN        186.0   \n",
       "1                 None            None         NaN        NaN        385.0   \n",
       "2                 None            None         NaN        NaN         85.0   \n",
       "3                 None            None         NaN        NaN        104.0   \n",
       "4                 None            None         NaN        NaN        104.0   \n",
       "...                ...             ...         ...        ...          ...   \n",
       "3461              None            None         NaN        NaN         87.0   \n",
       "3462              None            None         NaN        NaN        101.0   \n",
       "3463              None            None         NaN        NaN        101.0   \n",
       "3464              None            None         NaN        NaN        101.0   \n",
       "3465              None            None         NaN        NaN        101.0   \n",
       "\n",
       "      token_count                                               text  \n",
       "0            2455  τί γὰρ παθὼν ῥυθμίζεις με καὶ πρᾶον ἀποφῆναι γ...  \n",
       "1            5267  οὐδέν οὖν ἕτερον λέγεις ἤ ὅτι φιλοῦσι τούς πον...  \n",
       "2             941  καὶ μὴ ὡς ἐχθρὸν ἡγεῖσθε, ἀλλὰ νουθετεῖτε ὡς ἀ...  \n",
       "3           13729  εἰ δὲ δὴ θεῖον ἡ ἀλήθεια καὶ \" πάντων μὲν ἀγαθ...  \n",
       "4           13729  ἡμεῖς δέ, εἰ μηδαμῆ μηδαμῶς ἐπαινοῦμεν τὸ \" ἐρ...  \n",
       "...           ...                                                ...  \n",
       "3461         6386  ἦν μὲν γὰρ ἐστεφανωμένους ἰδεῖν, ἦν δὲ τοὺς αὐ...  \n",
       "3462         6645  τὸν δ’ ὑπὸ τοῦ ψόφου ταραχθέντα καὶ σπασάμενον...  \n",
       "3463         6645  ἐκεῖθεν δὲ ῥᾳδίως ἐπιβῆναι Μακεδονίας καὶ πολλ...  \n",
       "3464         6645  ἡ δὲ βουλὴ τῶν πεντακοσίων πυθομένη καὶ φοβηθε...  \n",
       "3465         6645   τὸ δὲ μῖγμα τῆς φωνῆς Μῆδον ἀποδηλοῖ τὸν ἐχθρόν·  \n",
       "\n",
       "[3466 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT t.sentence_id, w.*, s.text\n",
    "FROM tokens t\n",
    "JOIN works w ON t.grela_id = w.grela_id\n",
    "JOIN sentences s ON t.sentence_id = s.sentence_id\n",
    "WHERE w.lagt_provenience IN ('christian', 'pagan')\n",
    "  AND t.lemma IN ('ἐχθρός')\n",
    "  AND (\n",
    "    (w.not_before > 0 AND w.not_before < 600)\n",
    "    OR (w.not_after > 0 AND w.not_after < 600)\n",
    "  )\n",
    "'''\n",
    "df = conn.execute(query).fetchdf()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c588b848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 500 random christian and 500 random pagan rows\n",
    "df_christian = df[df['lagt_provenience'] == 'christian'].sample(n=500, random_state=42)\n",
    "df_pagan = df[df['lagt_provenience'] == 'pagan'].sample(n=500, random_state=42)\n",
    "\n",
    "df_sampled = pd.concat([df_christian, df_pagan], ignore_index=True)\n",
    "df_sampled.to_csv('../data/enemy_sample.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
